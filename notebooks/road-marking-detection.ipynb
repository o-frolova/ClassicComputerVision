{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opencv-python\n",
    "# %pip install numpy\n",
    "# %pip install typing\n",
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "import math\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../input_images/road1.png')\n",
    "image_copy = image.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the original image to HLS\n",
    "def convert_to_hls(img: np.ndarray) -> np.ndarray:\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "\n",
    "def isolate_white_color(hsl_img: np.ndarray, img: np.ndarray ) -> np.ndarray:\n",
    "    # Defining the lower and upper threshold for white in HLS\n",
    "    lower_white = np.array([0, 200, 0], dtype=np.uint8)     # Lower threshold for brightness, average saturation and hue\n",
    "    upper_white = np.array([255, 255, 255], dtype=np.uint8) # Upper threshold for brightness, saturation and hue\n",
    "\n",
    "    # Applying a threshold operation to isolate the white color in an HLS image\n",
    "    white_mask = cv2.inRange(hsl_img, lower_white, upper_white)\n",
    "    return cv2.bitwise_and(img, img, mask=white_mask)\n",
    "\n",
    "\n",
    "def gaussianBlur(img: np.ndarray) -> np.ndarray:\n",
    "    return cv2.GaussianBlur(img, (5, 5), 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbordersCanny(img: np.ndarray) -> np.ndarray:\n",
    "    return cv2.Canny(img, 100, 200)\n",
    "\n",
    "def limit_field_of_view(img: np.ndarray) -> np.ndarray:\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # Creating a mask for an area of interest\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    new_width = int(width) \n",
    "    new_height = int(height * 1.5)                  # 1.5 times increase in height\n",
    "    roi_y = (new_height - height) // 2              # shifting the area of interest down\n",
    "    roi_x = (width - new_width) // 2                # shifting the area of interest to the right\n",
    "    roi_corners = np.array([[(roi_x + 520, roi_y),  # offset from the left side by 520 pixels\n",
    "                            (width - roi_x, roi_y), \n",
    "                            (width - roi_x, new_height), \n",
    "                            (roi_x, new_height)]], dtype=np.int32) \n",
    "\n",
    "    cv2.fillPoly(mask, roi_corners, 255)\n",
    "\n",
    "    return cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "def get_Huff_lines(img: np.ndarray) -> np.ndarray:\n",
    "    return cv2.HoughLinesP(img, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removing unnecessary lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b>\n",
    "\n",
    "The resultant set of lines is partitioned into two clusters, distinguished based on their affiliation with the markings on the right and left sides of the road. Following this, within each cluster, the central line is determined by calculating the mean coordinates of the lines within that specific cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(lines: np.ndarray) -> np.ndarray:\n",
    "    features = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        angle = np.arctan2(y2 - y1, x2 - x1)\n",
    "        features.append([x1, y1, x2, y2, length, angle])\n",
    "    return np.array(features)\n",
    "\n",
    "def get_clusters_lines(lines: np.ndarray) -> list:\n",
    "    kmeans = KMeans(n_clusters=2) \n",
    "    features = extract_features(lines)\n",
    "    kmeans.fit(features)\n",
    "    clusters = [[] for _ in range(kmeans.n_clusters)]\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        cluster_idx = kmeans.labels_[i] \n",
    "        clusters[cluster_idx].append(line)\n",
    "    \n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_middle_line(lines: list) -> list:\n",
    "    # сalculation of the average coordinates of the start and end points for all lines\n",
    "    start_points = np.mean([line[0][:2] for line in lines], axis=0)\n",
    "    end_points = np.mean([line[0][2:] for line in lines], axis=0)\n",
    "    \n",
    "    # сalculating the midpoint for all lines\n",
    "    middle_point = tuple(((start_points + end_points) / 2).astype(int))\n",
    "\n",
    "    # сalculating the angle of inclination of the midline\n",
    "    angle = np.arctan2(end_points[1] - start_points[1], end_points[0] - start_points[0])\n",
    "\n",
    "    length = 280  \n",
    "    # starting point\n",
    "    x1 = middle_point[0] - int(length * np.cos(angle))\n",
    "    y1 = middle_point[1] - int(length * np.sin(angle))\n",
    "\n",
    "    # the end point\n",
    "    x2 = middle_point[0] + int(length * np.cos(angle))\n",
    "    y2 = middle_point[1] + int(length * np.sin(angle))\n",
    "\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def get_center_lines(clusters: list ) -> list:\n",
    "    center_lines = []\n",
    "    for cluster in clusters:\n",
    "        center_lines.append(find_middle_line(cluster))\n",
    "    return center_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding an intersection point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersection(center_lines: list) -> Tuple[int, int]:\n",
    "    x1, y1, x2, y2 = center_lines[0]\n",
    "    x3, y3, x4, y4 = center_lines[1]\n",
    "\n",
    "    # сalculation of angular coefficients of straight lines\n",
    "    m1 = (y2 - y1) / (x2 - x1) if (x2 - x1) != 0 else float('inf')\n",
    "    m2 = (y4 - y3) / (x4 - x3) if (x4 - x3) != 0 else float('inf')\n",
    "\n",
    "    # check the parallelism of the lines\n",
    "    if m1 == m2:\n",
    "        return None  \n",
    "\n",
    "    # сalculating the coordinates of the intersection point\n",
    "    if m1 == float('inf'):\n",
    "        x = x1\n",
    "        y = m2 * (x - x3) + y3\n",
    "    elif m2 == float('inf'):\n",
    "        x = x3\n",
    "        y = m1 * (x - x1) + y1\n",
    "    else:\n",
    "        x = ((m1 * x1 - y1) - (m2 * x3 - y3)) / (m1 - m2)\n",
    "        y = m1 * (x - x1) + y1\n",
    "\n",
    "    return int(x), int(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## presentation of results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_result(img: np.ndarray, lines: list, intersection_point: Tuple[int, int]) -> None:\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line\n",
    "            cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 10)\n",
    "\n",
    "    cv2.circle(img, tuple(intersection_point), 15, (0, 165, 255), -1)\n",
    "\n",
    "def save_image(img: np.ndarray, name: str) -> None:\n",
    "    cv2.imwrite(name, img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline of work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_image = convert_to_hls(image_copy)\n",
    "result_image = isolate_white_color(result_image, image_copy)\n",
    "result_image = gaussianBlur(result_image)\n",
    "result_image = getbordersCanny(result_image)\n",
    "result_image = limit_field_of_view(result_image)\n",
    "result_lines = get_Huff_lines(result_image)\n",
    "\n",
    "clusters = get_clusters_lines(result_lines)\n",
    "\n",
    "center_lines = get_center_lines(clusters)\n",
    "intersection_point = find_intersection(center_lines)\n",
    "\n",
    "draw_result(image, center_lines, intersection_point)\n",
    "save_image(image, '../output_images/result_road1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_origin = cv2.imread('../input_images/road1.png')\n",
    "combined_image = cv2.hconcat([image_origin, image])\n",
    "save_image(combined_image, '../output_images/result_road1_combined.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
